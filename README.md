# Transformers-in-Computer-Vision
Implementation of different Transformer architectures for vision tasks. 
Will soon features youtube tutorials on the different transformers/attention mechanisms.

Currently Features:
1. Vision Transformer (ViT)
2. Swin Transformer
3. Hybrid Attention Transformer (HAT) (Coming soon...)

# Hybrid Attention Transformer (HAT):
Original paper: https://arxiv.org/abs/2205.04437


Architecture:

![image](https://github.com/nickd16/Transformers-in-Computer-Vision/assets/108239710/5fe4230f-4d35-4d63-a0e2-376889a79d22)


Results:

![image](https://github.com/nickd16/Transformers-in-Computer-Vision/assets/108239710/500740a4-9dbd-4200-94f6-4c3be03720dc)
![image](https://github.com/nickd16/Transformers-in-Computer-Vision/assets/108239710/1324cbfd-94ad-4367-b6d5-c265ac8c4648)
![image](https://github.com/nickd16/Transformers-in-Computer-Vision/assets/108239710/a75cef94-8ea6-4cda-b75d-c73c74106092)
![image](https://github.com/nickd16/Transformers-in-Computer-Vision/assets/108239710/be8c6209-2998-47f5-855b-0a2a47a2374a)

# Swin Transformer: 
Original paper: https://arxiv.org/abs/2103.14030


Architecture:

![image](https://github.com/nickd16/Transformers-in-Computer-Vision/assets/108239710/59851228-a0c6-4b9a-b293-baea36eac55f)


# Vision Transformer (ViT):
Original paper: https://arxiv.org/abs/2010.11929

Architecture:

![image](https://github.com/nickd16/Transformers-in-Computer-Vision/assets/108239710/fcc0f03a-2e7c-41f1-b854-1ec1ab803c51)


