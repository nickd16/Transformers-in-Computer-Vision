# Transformers-in-Computer-Vision
Implementation of different Transformer architectures for vision tasks. 
Will soon features youtube tutorials on the different transformers/attention mechanisms.

Currently Features:
1. Vision Transformer (ViT)
2. Swin Transformer
3. Hybrid Attention Transformer (HAT) (Coming soon...)

# Hybrid Attention Transformer (HAT):
Original paper: https://arxiv.org/abs/2205.04437


Architecture:

![image](https://github.com/nickd16/Image-Upscaling-with-Hybrid-Attention-Transformer/assets/108239710/be1ffe75-31fa-400e-b83e-2412517982f3)

Results:
 
![image](https://github.com/nickd16/Image-Upscaling-with-Hybrid-Attention-Transformer/assets/108239710/cae184a2-3b49-47e1-8211-9f5675ffed95)
![image](https://github.com/nickd16/Image-Upscaling-with-Hybrid-Attention-Transformer/assets/108239710/f6fba0ca-ac86-4b5e-a5b4-b6d08fcde33f)
![image](https://github.com/nickd16/Image-Upscaling-with-Hybrid-Attention-Transformer/assets/108239710/16a37d83-8a19-404f-92a0-715547998a3b)
![image](https://github.com/nickd16/Image-Upscaling-with-Hybrid-Attention-Transformer/assets/108239710/a07f033a-ede4-473c-9373-bf58bd60446f)

# Swin Transformer: 
Original paper: https://arxiv.org/abs/2103.14030


Architecture:

![image](https://github.com/nickd16/Transformers-in-Computer-Vision/assets/108239710/59851228-a0c6-4b9a-b293-baea36eac55f)


# Vision Transformer (ViT):
Original paper: https://arxiv.org/abs/2010.11929

Architecture:

![image](https://github.com/nickd16/Transformers-in-Computer-Vision/assets/108239710/fcc0f03a-2e7c-41f1-b854-1ec1ab803c51)


